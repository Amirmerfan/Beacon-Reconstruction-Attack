{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import hamming\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from Module import ReconstructionTool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "# Set individuals count for analysis\n",
    "individuals = [50]\n",
    "snp_count = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'beacon.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m accuracies = []\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load data files\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m beacon = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbeacon.npy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoaded beacon data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBeacon data loaded. Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbeacon.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Amir\\Desktop\\CS577\\Project\\Beacon-Reconstruction-Attack\\.venv\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:454\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    452\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    455\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'beacon.npy'"
     ]
    }
   ],
   "source": [
    "# Arrays to store results\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "# Load data files\n",
    "beacon = np.load(\"beacon.npy\")\n",
    "print(\"Loaded beacon data...\")\n",
    "print(f\"Beacon data loaded. Shape: {beacon.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual count: 50\n",
      "--------------------------------------------------------------------------------\n",
      "Loading correlation matrix...\n",
      "(30, 30) Initial Corr\n",
      "Beacon partitioning for 50 individuals. Shape: (30, 50)\n",
      "(30, 50)\n",
      "Number of ones in beacon: 351.0\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 1. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 1. ... 1. 0. 0.]] Initial Beacon\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 1. 0. 0.]] Initial Reconstructed Beacon\n",
      "Number of ones in reconstructed beacon: 351.0\n"
     ]
    }
   ],
   "source": [
    "for ind_count in individuals:\n",
    "    print(\"Individual count:\", ind_count)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Load and slice the initial correlation matrix\n",
    "    print(\"Loading correlation matrix...\")\n",
    "    corr1 = np.load(\"OpenSNP.npy\")\n",
    "    corr1 = corr1[:snp_count , :100]\n",
    "\n",
    "    # Calculate correlations using the class\n",
    "    corr_tool = ReconstructionTool(corr1)\n",
    "    corr = corr_tool.calculate_correlations(corr1)\n",
    "    print(corr.shape, \"Initial Corr\")\n",
    "\n",
    "    # Create tensor of correlations\n",
    "    corr = torch.tensor(corr, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "    # Slice the beacon for the first `ind_count` individuals\n",
    "    beacon = beacon[:snp_count , :ind_count]\n",
    "    print(f\"Beacon partitioning for {ind_count} individuals. Shape: {beacon.shape}\")\n",
    "    beacon_tool = ReconstructionTool(beacon)\n",
    "    print(beacon.shape)\n",
    "    number_of_ones = np.sum(beacon)\n",
    "    print(\"Number of ones in beacon:\", number_of_ones)\n",
    "    print(beacon, \"Initial Beacon\")\n",
    "\n",
    "    # Query and reconstruct beacon\n",
    "    reconstructed_beacon = beacon_tool.query(proportion=1.0)\n",
    "    print(reconstructed_beacon, \"Initial Reconstructed Beacon\")\n",
    "    print(\"Number of ones in reconstructed beacon:\", number_of_ones)\n",
    "    reconstructed_beacon = beacon_tool.compare_and_sort_columns(beacon, reconstructed_beacon)\n",
    "    \n",
    "    number_of_ones = np.sum(reconstructed_beacon)\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 1. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]] Sorted Reconstructed Beacon\n"
     ]
    }
   ],
   "source": [
    "# Training loop setup\n",
    "EPOCHS = 1001\n",
    "EPOCHS1 = 501\n",
    "max_iterations = 3000\n",
    "iteration = 0\n",
    "converged = False\n",
    "target_frequencies = torch.tensor(np.sum(beacon, axis=1), dtype=torch.float32)\n",
    "prev_reconstructed_beacon = None  \n",
    "\n",
    "\n",
    "while iteration < max_iterations:\n",
    "    iteration += 1\n",
    "        # Stage 1: Optimize correlations\n",
    "    reconstructed_beacon_tensor = torch.tensor(reconstructed_beacon, dtype=torch.float32, requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([reconstructed_beacon_tensor], lr=0.001)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        optimizer.zero_grad()\n",
    "        loss = torch.norm(corr_tool.calculate_correlations(reconstructed_beacon_tensor) - corr, p='fro')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if epoch % 100 == 0:\n",
    "        #     print(f'Iteration {iteration}, Epoch {epoch}, loss {loss.item()}')\n",
    "\n",
    "    # print(reconstructed_beacon, \"Reconstructed Beacon\")\n",
    "\n",
    "        # Stage 2: Optimize for SNP frequencies\n",
    "    reconstructed_beacon_tensor = torch.tensor(reconstructed_beacon, dtype=torch.float32, requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([reconstructed_beacon_tensor], lr=0.001)\n",
    "\n",
    "    for epoch in range(EPOCHS1):\n",
    "        optimizer.zero_grad()\n",
    "        freq_loss = beacon_tool.frequency_loss(reconstructed_beacon_tensor, target_frequencies)\n",
    "        freq_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if epoch % 100 == 0:\n",
    "        #     print(f'Iteration {iteration}, Epoch {epoch}, Frequency loss: {freq_loss.item()}')\n",
    "\n",
    "    reconstructed_beacon = (reconstructed_beacon_tensor.detach().numpy() > 0.5).astype(int)\n",
    "    # print(reconstructed_beacon, \"Frequency-Optimized Reconstructed Beacon\")\n",
    "\n",
    "    # Convergence check based on flips\n",
    "    if prev_reconstructed_beacon is not None:\n",
    "        # Count the number of flips between current and previous beacons\n",
    "        flips = np.sum(reconstructed_beacon != prev_reconstructed_beacon)\n",
    "        \n",
    "\n",
    "        # Check if flips are less than 10\n",
    "        if flips < 10:\n",
    "            converged = True\n",
    "            break\n",
    "\n",
    "    # Update previous beacon\n",
    "    prev_reconstructed_beacon = reconstructed_beacon.copy()\n",
    "\n",
    "\n",
    "\n",
    "new_beacon = beacon_tool.compare_and_sort_columns(beacon, reconstructed_beacon)\n",
    "print(new_beacon, \"Sorted Reconstructed Beacon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "accuracy = beacon_tool.calculate_accuracy(beacon, new_beacon)\n",
    "precision = beacon_tool.calculate_precision(beacon, new_beacon)\n",
    "recall = beacon_tool.calculate_recall(beacon, new_beacon)\n",
    "f1 = beacon_tool.calculate_f1(beacon, new_beacon)\n",
    "\n",
    "accuracies.append(accuracy)\n",
    "precisions.append(precision)\n",
    "recalls.append(recall)\n",
    "f1_scores.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individuals\tAccuracy\tPrecision\tRecall\t\tF1 Score\n",
      "50\t\t0.901\t\t0.801\t\t0.766\t\t0.783\n"
     ]
    }
   ],
   "source": [
    "#print the results in a table format, with .3f precision, save\n",
    "print(\"Individuals\\tAccuracy\\tPrecision\\tRecall\\t\\tF1 Score\")\n",
    "# print the result of the initial beacon\n",
    "\n",
    "for i in range(len(individuals)):\n",
    "    print(f\"{individuals[i]}\\t\\t{accuracies[i]:.3f}\\t\\t{precisions[i]:.3f}\\t\\t{recalls[i]:.3f}\\t\\t{f1_scores[i]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
